# -GENERATIVE-TEXT-MODEL

*COMPANY*: CODTECH IT SOLUTIONS

*NAME*:  NALLAGATLA ADITHYA

*INTERN ID*: CT04DM719

*DOMAIN*: Artificial intelligence

*DURATION*:  4 weeks

*MENTOR*:  Neela Santhosh

**discriptiom:This Python script, executed on the Google Colab platform, showcases a text generation task using a pretrained GPT-2 language model from the Hugging Face Transformers library, in combination with PyTorch. The code imports essential tools such as GPT2LMHeadModel and GPT2Tokenizer to handle model inference and token processing, while leveraging PyTorch's torch.device to automatically detect and utilize GPU acceleration, if available. The model is set to evaluation mode to ensure deterministic behavior during inference. A text generation function, generate_text, takes an input prompt, tokenizes it, and then generates a response using sampling parameters like top_k, top_p, temperature, and no_repeat_ngram_size to enhance creativity and coherence. Multiple prompts such as “The future of artificial intelligence is” and “Once upon a time in a village” are passed to the function, producing unique, contextually relevant completions. Google Colab’s GPU-backed environment makes this possible even without local high-end hardware, enabling efficient experimentation in natural language processing tasks. The application areas for such text generation include creative writing, storytelling, virtual assistants, marketing content automation, medical documentation, and educational tools. This project demonstrates how powerful AI capabilities can be accessed and integrated using open-source tools and cloud infrastructure, lowering the barrier for developers and researchers to explore advanced NLP tasks.
